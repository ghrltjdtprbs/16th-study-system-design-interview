#12장. 전자 지갑

## 목표

전자 지갑 서비스를 설계하라.

- 결제 기능
- 송금 기능
    - 전자 지갑 간 이체는 은행 간 이체보다 빠름
    - 일반적으로 추가 수수료 부과 X

## 1단계. 문제 이해 및 설계 범위 확정

- 기능: 전자 지갑 사이 이체에만 집중
- TPS: 100만 TPS
- 정확성 요건: 데이터베이스가 제공하는 트랜잭션 보증으로 충분
- 정확성 증명: 일반적으로 트랜잭션이 완료된 뒤에나 확인
    - 그 외 검증 방법
        - 내부 기록과 은행 명세서 비교: 조정 작업으로는 데이터 일관성 깨짐을 알 수는 있지만, 원인 분석은 어려움
        - 따라서, **재현성을 갖춘 시스템을 설계**: 처음부터 데이터를 재생하여 언제든지 과거 잔액을 재구성할 수 있는 시스템
- 가용성: 99.99% 가정
- 환전 여부: 미지원

### 개략적 추정

- 사용할 데이터베이스는 1000TPS 지원 가능하다고 가정
- 200만(100만 * 2) TPS 지원 위해서는 대략 2000개 노드 필요
    - 이체 명령은 두 번의 연산 필요
        - 인출 연산
        - 입금 연산
- 한 노드가 처리 가능한 TPS가 늘어날 수록, 총 노드 수 줄어들어 하드웨어 비용 낮아지므로, 이번 설계 목표 중 하나는 **단일 노드가 처리 가능한 트랜잭션 수를 늘리는 것**

## 2단계. 개략적 설계안 제시 및 동의 구하기

- API 설계
- 3가지 개략적 설계안
    1. 간단한 메모리 기반 솔루션
    2. 데이터베이스 기반 분산 트랜잭션 솔루션
    3. 재현성을 갖춘 이벤트 소싱 솔루션

### API 설계

- POST `/v1/wallet/balance_transfer`
    - 한 지갑에서 다른 지갑으로 자금 이체
    - 요청 인자
        - from_account: 자금을 인출할 계좌
        - to_account: 자금을 입금할 계좌
        - amount: 이체할 금액
        - currency: 통화 단위
        - transaction_id: 중복 제거에 사용할 ID

### 1. 간단한 메모리 기반 솔루션: 인메모리 샤딩

- 지갑 애플리케이션은 모든 사용자 계정의 잔액을 유지
- <사용자, 잔액> -> map(해시 테이블) or 키-값 저장소
- redis
    - 1대로 100만 TPS는 벅참
    - 클러스터를 구성하고 사용자 계정을 모든 노드에 균등 분산: 파티셔닝, 샤딩
- 주키퍼
    - 설정 정보 전문 저장소
    - 높은 가용성 보장
    - 모든 레디스 노드의 파티션 수 및 주소는 한군데(ex: 주키퍼)에 저장
- 지갑 서비스
    - 이체 명령 처리 담당
    - 무상태 서비스: 수평적 규모 확장 용이

    1. 이체 명령 수신
    2. 이체 명령 유효성 검증
    3. 명령 유효성 검증 시 이체에 관계된 두 계정의 잔액 갱신
- 문제점: **정확성 요구사항 미충족**
    - 지갑 서비스 이체마다 두 개 레디스 노드 업데이트 시 두 연산 모두 성공하리라는 보장 없음
    - **두 연산이 원자적 트랜잭션으로 실행되어야 함**

### 2. 데이터베이스 기반 분산 트랜잭션 솔루션

#### 데이터베이스 샤딩

- 서로 다른 두 개 저장소 노드 갱신 연산을 원자적을 수행하려면?
  -> 각 레디스 노드를 트랜잭션을 지원하는 관계형 데이터베이스 노드로 교체
- 서로 다른 두 연산이 원자적으로 동작하도록 하려면?
  -> **분산 트랜잭션**

#### 저수준 방안. 분산 트랜잭션: 2단계 커밋

- 분산 시스템에서 한 트랜잭션에는 여러 노드의 프로세스가 관여할 수 있음
- 분산 트랜잭션은 이들 프로세스를 원자적인 하나의 트랜잭션으로 묶는 방안
- 저수준 방안
- 데이터베이스 자체에 의존
- 2단계 커밋 알고리즘

<img alt="image" src="https://github.com/user-attachments/assets/e7bb8ee7-9416-49e7-aa88-9ae59d8bbd5e">

- 준비 단계 실행 위해서는 데이터베이스 실행 방식 변경해야 함
    - 이기종 데이터베이스 사이에 2PC 실행 위해서는 모든 데이터베이스가 X/Open XA 표준을 만족해야함
    - 다른 노드 메시지 기다리는 동안 락이 오랫동안 잠긴 상태로 남을 수 있어 성능이 좋지 않음
    - 조정자가 SPOF 지점

#### 고수준 방안. 분산 트랜잭션: TC/C

- Try-Confirm/Cancel
    1. 조정자는 모든 데이터베이스에 트랜잭션에 필요한 자원 예약 요청
    2. 조정자는 모든 데이터베이스로부터 회신 받음
        - 모두 yes: 조정자는 모든 데이터베이스에 작업 확인 요청: `시도-확정` 절차
        - 하나라도 no: 조정자는 모든 데이터베이스에 작업 취소 요청: `시도-취소` 절차

<img alt="image" src="https://github.com/user-attachments/assets/99ff0ba9-737e-442c-8f6f-2c52fb9cb8c0">

- 2PC와의 차이점
    - 2PC는
        - 하나의 트랜잭션 -> 2단계 시작 시점에 모든 로컬 트랜잭션이 끝나지 않았고, 락도 잠겨 있는 상태
        - 두번째 단계에 미완성된 트랜잭션을 중단하거나 커밋하여 끝냄
    - TC/C는
        - 각 단계가 별도 트랜잭션 -> 2단계 시작 시점에 모든 로컬 트랜잭션 완료된 상태이며, 락도 풀린 상태
        - 오류가 발생했을 때 이전 트랜잭션 결과를 상쇄하는 새로운 트랜잭션 실행

- 보상 기반 분산 트랜잭션이라고도 부름
    - 실행 취소 절차를 비즈니스 로직으로 구현하므로 고수준 해법
        - 장점: 특정 데이터베이스에 구애받지 않음: 트랜잭션 지원하기만 하면 TC/C는 작동
        - 단점: 애플리케이션 계층의 비즈니스 로직에서 세부 사항을 관리하고 분산 트랜잭션의 복잡성을 처리해야 함

- 단계별 상태 테이블
    - TC/C 실행 도중 지갑 서비스가 다시 시작되면 어떻게 되나?
        - 과거 모든 작업 기록이 사라질 수 있으며, 어떻게 복구해야할 지 알 수 없게 됨
    - 해결 방안: TC/C의 진행 상황, 특히 각 단계 상태 정보를 트랜잭션 데이터베이스에 저장
        - 분산 트랜잭션의 ID와 내용
        - 각 데이터베이스에 대한 'Try' 단계의 상태: not semt yet, has been set, response received
        - 두 번째 단계의 이름: confirm, cancel
        - 두 번째 단계의 상태
        - 순서가 어긋났음을 나타내는 플래그
    - 어디에 저장할 것인가?
        - 일반적으로 돈을 인출할 지갑의 계정이 있는 데이터베이스에 배치

- 불균형 상태
    - 1단계가 끝난 시점에는 잔액 총합이 동일해야 한다는 회계 기본 원칙 위반
    - TC/C는 여러 개의 독립적인 로컬 트랜잭션으로 구성되며, 실행 주체는 애플리케이션
        - 애플리케이션은 이런 독립적인 로컬 트랜잭션이 만드는 중간 결과를 볼 수 있음 (<-> 데이터베이스 트랜잭션/2PC 같은 분산 트랜잭션은 중간 실행 결과 알 수 없음)
        - 분산 트랜잭션 실행 도중에는 항상 데이터 불일치가 발생하는데, 하위 시스템에서 불일치를 수정하는 경우에는 그 사실을 알 필요 없지만, 그렇지 않다면 우리가 직접 처리해야 함

- 유효한 연산 순서 (이해 안됨)
    - 시도 단계에서 연산 경우의 수
        1. A: -$1, C: NOP -> YES
        2. A: NOP, C: +$1 -> NO: C 연산 성공, A 연산 실패 시 취소 단계 실행 필요한데, C에서 그 사이에 누가 $1을 이체했다면, 잔액 부족 (트랜잭션 보증 위반)
        3. A: -$1, C: +$1 -> NO: 둘 중 하나의 연산이 실패한다면 문제 발생

- 잘못된 순서로 실행된 경우
    - 해결 방안
        - 취소 명령이 먼저 도착하면 데이터베이스에 아직 상응하는 시도 명령을 못 보았음을 나타내는 플래그를 참으로 설정하여 저장
        - 시도 명령 도착하면 항상 먼저 도착한 취소 명령이 있었는지 확인하여 있었으면 바로 실패 반환

<img alt="image" src="https://github.com/user-attachments/assets/c76c3413-5b20-4869-bc0d-0e57cdddaed8">

#### 분산 트랜잭션: 사가

- 유명한 분산 트랜잭션 솔루션 가운데 하나로 마이크로 서비스 아키텍처에서는 사실상 표준
- 선형적 명령 수행
    1. 모든 연산은 순서대로 정렬된다. 각 연ㅅ나은 자기 데이터베이스에 독립 트랜잭션으로 실행
    2. 연산은 첫 번째부터 마지막까지 순서대로 실행된다. 한 연산이 완료되면 다음 연산이 개시된다.
    3. 연산이 실패하면 전체 프로세스는 실패한 연산부터 맨 처음 연산까지 역순으로 보상 트랜잭션을 통해 롤백된다.

    - 즉, n개 연산 실행하는 분산 트랜잭션은 2n개 연산을 준비해야 함
- 유효한 연산 순서 조율 방법
    1. 분산 조율: 마이크로서비스 아키텍처에서 사가 분산 트랜잭션에 관련된 모든 서비스가 다른 서비스의 이벤트를 구독하여 작업을 수행하는 방식. 완전히 탈 중앙화된 조율 방식
    2. 중앙 집중형 조율: 하나의 조정자가 모든 서비스가 올바른 순서로 작업을 실행하도록 조율

    - 방법은 사업상의 필요와 목표에 따라 결정
        - 분산 조율 방식은 서비스가 서로 비동기식으로 통신
            - 모든 서비스는 다른 서비스가 발생시킨 이벤트의 결과로 어떤 작업을 수행할지 정하기 위해 내부적으로 상태 기계 유지
            - 서비스가 많으면 관리 어려워짐
        - 따라서 일반적으로는 복잡한 상황을 잘 처리하는 중앙 집중형 조율 방식을 선호
- TC/C vs SAGA

  | 항목                            | TC/C                        | 사가                                  |
    |-------------------------------|-----------------------------|--------------------------------------|
  | 보상 트랜잭션 실행               | 취소 단계에서                  | 롤백 단계에서                           |
  | 중앙 조정                       | 예                           | 예(중앙 집중형 조율 모드에서만)            |
  | 작업 실행 순서                  | 임의                          | 선형                                   |
  | 병렬 실행 가능성                | 예                           | 아니요(선형적 실행)                     |
  | 일시적으로 일관되지 않은 상태 허용 | 예                           | 예                                     |
  | 구현 계층: 애플리케이션 또는 데이터베이스 | 애플리케이션                  | 애플리케이션                           |

    - 실무에서는 어떤 방법이 좋을까? **지연 시간 요구사항에 따라 다름!**
        - 사가는 연산을 순서대로 해야함 vs TC/C에서는 병렬로 실행 가능

        1. 지연 시간 요구사항이 없거나 앞서 살펴본 송금 사례처럼 서비스 수가 매우 적다면 아무거나 사용
        2. 지연 시간에 민감하고 많은 서비스/운영이 관계된 시스템이라면 TC/C가 나음

- 분산 트랜잭션 방안이 제대로 작동하지 않는 케이스
    - ex) 사용자가 애플리케이션 수준에서 잘못된 작업을 입력(입력된 금액 자체가 잘못된 등)
    - 따라서, 문제의 근본 원인을 역추적하고 모든 계정에서 발생하는 연산을 감사할 방법이 있다면 좋을 것 같은데 어떻게? **이벤트 소싱!**

### 이벤트 소싱

#### 배경

- 특정 시점의 계정 잔액을 알 수 있나?
- 과거 및 현재 계정 잔액이 정확한지 어떻게 알 수 있나?
- 코드 변경 후에도 시스템 로직이 올바른지 어떻게 검증할 것인가?
  -> **DDD에서 개발된 기법인 이벤트 소싱!**으로 위 질문들에 체계적으로 답할 수 있다.

#### 정의

- 이벤트 소싱의 네 가지 중요한 용어
    - 명령: 외부에서 전달된, 의도가 명확한 요청
        - 이벤트 소싱에서 순서는 매우 중요하므로, 일반적으로 FIFO 큐에 저장
    - 이벤트: 명령 이행 결과
        - 명령은 의도가 명확하지만, 사실은 아니다 == 유효하지 않다.
        - 명령과 이벤트의 차이점
            - 이벤트는 검증된 사실 == 실행이 끝난 상태 : 과거형
            - 명령은 무작위성이나 I/O가 포함될수 있지만, 이벤트는 "결정론적"
        - 이벤트 생성 프로세스 특성
            - 하나의 명령으로 여러 이벤트 생성 가능
            - 이벤트 생성 과정에는 무작위성이 개입될 수 있어서, 같은 명령에 항상 동일한 이벤트가 만들어진다는 보장 없음
        - 이벤트도 명령 순서에 따르므로, FIFO 큐에 저장
    - 상태: 이벤트가 적용될 때 변경되는 내용
    - 상태 기계: 이벤트 소싱 프로세스를 구동
        - 결정론적으로 동작
        - 무작위성 내포 불가
        - 이벤트 상태 반영은 항상 같은 결과를 보장

        1. 명령의 유효성을 검사하고, 이벤트를 생성
        2. 이벤트를 적용하여 상태를 갱신

#### 지갑 서비스 예시

- 명령: 이체 요청
    - FIFO 큐에 기록 (카프카)
- 상태: 계정 잔액 -> 관계형 DB에 있다고 가정
- 상태 기계
    - 동작 과정
        1. 상태 기계는 명령을 큐에 들어간 순서대로 확인
        2. 명령 하나를 읽을 때마다 계정에 충분한 잔액이 있는지 확인
        3. 충분하다면, 상태 기계는 각 계정에 대한 이벤트 생성
        4. 다음 이벤트를 읽음
        5. 데이터베이스의 잔액을 갱신하여 이벤트 적용을 마침

#### 재현성

- 이벤트 소싱이 다른 아키텍처에 비해 갖는 가장 중요한 장점
    - 분산 트랜잭션 방안에서 지갑 서비스는 갱신한 계정 잔액을 데이터베이스에 저장
        - 계정 잔액이 변경된 이유는 알기 어려움
        - 과거 잔액은 알기 어려움
        - 특정 시점의 잔액만 알 수 있음
    - 이벤트를 처음부터 다시 재생하면 과거 잔액 상태는 언제든 재구성 가능
        - 이벤트 리스트는 불변이고, 상태 기계 로직은 결정론적이므로 이벤트 이력을 재생하여 만들어낸 상태는 언제나 동일
- 앞선 질문에 대한 대답
    1. 시작부터 계정 잔액을 알고 싶은 시점까지 이벤트를 재생하면 됨
    2. 이벤트 이력에서 계정 잔액을 다시 계산해 보면 잔액이 정확한지 확인 가능
    3. 새로운 코드에 동일한 이벤트 이력을 입력으로 주고 같은 결과가 나오는지 보면 됨

**감사 가능한 시스템이어야 한다는 요건으로 인해 이벤트 소싱이 지갑 서비스 구현의 실질적인 솔루션으로 채택되는 경우 많음**

#### 명령-질의 책임 분리 (CQRS)

- 클라이언트는 여전히 계정 잔액을 알 수 없음
- 이벤트 소싱 프레임워크 외부의 클라이언트가 상태를 알도록 할 방법 필요
- 직관적인 해결책 하나는 상태 이력 데이터베이스의 읽기 전용 사본을 생성한 다음 외부와 공유
- 이벤트 소싱은 이와는 조금 다른 해결책 제시
    - 이벤트 소싱은 상태, 즉 계정 잔액을 공개하는 대신, 모든 이벤트를 외부에 전송
    - 이벤트를 수신하는 측에서 직접 상태를 재구축
    - 이러한 설계 철학을 CQRS라고 함
- 상태 기록 담당 상태 기계 1개, 읽기 전용 상태 기계 n개
    - 읽기 전용 상태 기계는 상태 뷰를 생성하고, 이 뷰는 질의에 이용됨
    - 읽기 전용 상태 기계는 다양한 상태 표현을 도출하고, 별도 데이터베이스에 기록하는 등의 작업을 할 수 있음
    - 실제 상태에 어느 정도 뒤쳐질 수 있으나, 결과적 일관성 모델에 따름

- 지금의 이벤트 소싱 아키텍처는 한 번에 하나의 이벤트만 처리하는 데다 여러 외부 시스템과 통신해야 하는데, 더 빠르게 만들 수 없을까?

## 3단계. 상세 설계

- 높은 성능과 안정성 및 확장성 달성 위한 기술

### 고성능 이벤트 소싱

#### 파일 기반의 명령 및 이벤트 목록

- 명령과 이벤트를 카프카 같은 원격 저장소 대신 로컬 디스크에 저장하는 방안
    - 네트워크 전송 시간 절약
- 이벤트 목록은 추가 연산만 가능한 자료 구조에 저장
    - 추가는 순차적 쓰기 연산이므로, 일반적으로 매우 빠름
    - 운영체제는 보통 순차적 읽기 및 쓰기 연산에 엄청나게 최적화되어 있으므로 HDD에서도 잘 동작
    - 순차적 디스크 접근은 무작위 메모리 접근보다 빠를 수도 있음
- 최근 명령과 이벤트를 메모리에 캐시
- 구체적인 구현 방법
    - mmap 기술
        - 로컬 디스크에 쓰는 동시에, 최근 데이터는 메모리에 자동으로 캐싱 가능
        - 디스크 파일을 메모리 배열에 대응 시킴
        - 운영 체제는 파일의 특정 부분을 메모리에 캐시하여 읽기 및 쓰기 연산의 속도 높임
        - 추가만 가능한 파일에 이루어지는 연산의 경우 필요한 모든 데이터는 거의 항상 메모리에 있으므로 실행 속도 증가

#### 파일 기반 상태

- 파일 기반 로컬 관계형 DB(SQLite)나 로컬 파일 기반 키-값 저장소(RocksDB) 사용
- RocksDB 사용
    - 쓰기 작업에 최적화된 자료구조 LSM을 사용
- 최근 데이터는 캐시하여 읽기 성능 향상

<img alt="image" src="https://github.com/user-attachments/assets/a47bba1a-e999-4c1a-90c1-7eaafbe44065">

#### 스냅샷

- 과거 특정 시점의 상태로, 변경 불가
- 모든 것이 파일 기반일 때 재현 프로세스의 속도 높일 방법
- 주기적으로 상태 기계를 멈추고, 현재 상태를 파일에 저장한다면 시간 절약 가능
- 상태 기계는 더 이상 최초 이벤트에서 시작할 필요 없음
- 이진 파일 형태로, HDFS 같은 객체 저장소에 저장

<img alt="image" src="https://github.com/user-attachments/assets/54c16632-93c4-404c-8af5-97fc91ac87ae">

정리하자면, 이벤트 소싱 아키텍처는 애초에 이벤트 목록을 선형적으로 처리하므로 HDD나 운영체제 캐시와 궁합이 잘 맞는다.
하지만, **로컬 디스크에 데이터를 저장하는 서버는 더 이상 무상태가 아니므로, SPOF가 된다. 안정성은 어떻게 개선할래?**

### 신뢰할 수 있는 고성능 이벤트 소싱

#### 신뢰성 분석

- 데이터 내구성이 보장되는 한, 계산 결과는 코드를 다른 노드에서 돌리면 되는 것 == 데이터 신뢰성이 매우 중요
- 현재 데이터 유형 및 신뢰성 보장 방법
    - 파일 기반 명령 -> 이벤트가 만들어지는 기반, 신뢰성 보장 필요, 하지만 **이벤트 생성 자체는 결정론적 과정이 아니므로, 명령의 신뢰성 만으로는 이벤트의 재현성 보장 불가**
    - 파일 기반 이벤트 -> 이벤트는 불변, 과거의 사실 == **높은 신뢰성을 보장할 유일한 데이터는 이벤트**
    - 파일 기반 상태 -> 이벤트 목록 재생하여 언제든 다시 만들 수 있음
    - 상태 스냅샷 -> 이벤트 목록 재생하여 언제든 다시 만들 수 있음

#### 합의

- 높은 안정성을 위해서는 이벤트 목록을 여러 노드로 복제
    1. 데이터 손실 없음 보장
    2. 로그 파일 내 데이터의 상대적 순서는 모든 노드에서 동일 보장
       -> **합의 기반 복제 방안**이 적합

    - 모든 노드가 동일한 이벤트 목록에 합의하도록 보장
    - ex) Raft 알고리즘 (이해 안됨)
        - 노드의 절반 이상이 온라인 상태면 그 모두에 보관된 추가 전용 리스트는 같은 데이터를 가진다.
        - 즉, 절반 이상 온라인 상태면 시스템은 정상 작동 한다.
        - 노드 역할 종류: 리더, 후보, 팔로어
            - 리더: 최대 하나: 외부 명령을 수신하고, 클러스터 노드 간 데이터를 안정적으로 복제하는 역할
            - 나머지 노드: 팔로어

#### 고신뢰성 솔루션

- 복제 메커니즘으로 파일 기반 이벤트 소싱 아키텍처에서 단일 장애 지점 문제 제거 가능
    - 3개 이벤트 소싱 노드가 있을 때, 노드들을 래프트 알고리즘으로 이벤트 목록을 안정적으로 동기화
    - 리더: 외부 사용자로부터 들어오는 명령 요청을 받아 이벤트로 변환하고 로컬 이벤트 목록에 추가
    - 래프트 알고리즘은 새로운 이벤트를 모든 팔로어에 복제
        - 리더와 팔로어가 동일한 이벤트 목록을 갖도록 하며, 이벤트 소싱은 동일한 이벤트 목록에서 항상 동일한 상태가 만들어지도록 함
        - 장애 처리 전략
            - 리더 장애 발생 -> 래프트 알고리즘은 나머지 정상 노드 중에서 새 리더 선출
            - 리더 장애가 명령 목록이 이벤트로 변환되기 전에 발생하는 경우 -> 클라이언트는 시간 초과 또는 오류 응답을 받으므로, 새로 선출된 리더에게 같은 명령 재전송
            - 팔로어 장애 발생 -> 해당 팔로어로 전송된 요청은 실패하고, 래프트는 죽은 노드가 다시 시작되거나, 새로운 노드로 대체될 때까지 기한 없이 재시도

그렇다면, 시스템의 안정성과 결함 내성은 향상 되었다.
하지만, 100만 TPS를 처리하려면 서버 한 대로는 부족한데, 어떻게 확장성을 높일까?

### 분산 이벤트 소싱

- 현재까지 아키텍처에서의 문제점
    - 전자 지갑 업데이트 결과는 즉시 받고 싶어요!
        - CQRS 시스템에서는 요청/응답 흐름 느림
        - 클라이언트가 디지털 지갑의 업데이트 시점을 정확히 알 수 없어서 주기적 폴링에 의존 필요
    - 단일 래프트 그룹의 용량 제한 문제
        - 일정 규모 이상에서는 데이터 샤딩하고 분산 트랜잭션 구현 필요
- 해결 방안: 풀 vs 푸시

#### 풀 모델

- 외부 사용자가 읽기 전용 상태 기계에서 주기적으로 실행 상태 조회
- 실시간 아님, 주기 짧으면 지갑 서비스에 과부하
- 외부 사용자와 이벤트 소싱 노드 사이에 리버스 프록시 추가하여 개선
    - 외부 사용자 -> 리버스 프록시: 명령 전송
    - 리버스 프록시 -> 이벤트 소싱 노드: 명령 전달 & 주기적으로 실행 상태 질의
    - 클라이언트 로직 단순화 BUT 여전히 실시간 아님

#### 풀 모델

- 대신 리버스 프록시를 추가함으로써, 읽기 전용 상태 기계를 수정하여 응답 속도 향상 가능
    - 읽기 전용 상태 기계는 자기만의 특별한 로직 가질 수 있음 -> **이벤트를 수신하자마자 실행 상태를 리버스 프록시에 푸시**
    - 실시간으로 응답이 이루어지는 느낌은 줄 수 있음

#### 분산 트랜잭션

- 모든 이벤트 소싱 그룹이 동기적 실행 모델을 채택하면 TC/C나 SAGA 같은 분산 트랜잭션 솔루션을 재사용할 수 있음

<img alt="image" src="https://github.com/user-attachments/assets/9edb97ec-a6e4-44df-b962-e6fa7e3ac837">

- 이체 동작 흐름
    - 사가 분산 트랜잭션 모델을 사용하여 롤백 없이 정상 실행이 이루어지는 경로
    - 송금 연산: 2개의 분산 연산 필요
        - A: -$1
        - C: +$1

        1. 사용자 A가 사가 조정자에게 분산 트랜잭션 전송

        - A: -$1
        - C: +$1

        2. 사가 조정자는 단계별 상태 테이블에 레코드 생성하여 트랜잭션 상태 추적
        3. 사가 조정자는 작업 순서를 검토하여 A 먼저 처리 결정하여, A 정보가 들어있는 파티션 1에 전송
        4. 파티션 1의 래프트 리더는 명령을 수신하고, 명령 목록에 저장
            - 이후에 명령 유효성 검사하여, 유효하면 이벤트로 변환
            - 래프트 알고리즘은 여러 노드 사이에 이벤트 데이터 동기화
            - 동기화 완료 시 이벤트 실행
        5. 이벤트 동기화되면 파티션 1의 이벤트 소싱 프레임워크가 CQRS를 사용하여 데이터를 읽기 경로로 동기화
            - 읽기 경로는 상태 및 실행 상태 재구성
        6. 파티션 1의 읽기 경로는 이벤트 소싱 프레임워크를 호출한 사가 조정자에게 상태 푸시
        7. 사가 조정자는 파티션 1에서 성공 상태 수신
        8. 사가 조정자는 단계별 상태 테이블에 파티션 1의 작업이 성공했음을 나타내는 레코드 생성
        9. 첫 작업이 성공했으므로 사가 조정자는 두 번째 작업인 C를 실행
            - 조정자는 계정 C가 있는 파티션 2에 명령 전송
        10. 파티션 2의 래프트 리더가 C 명령을 수신하여 명령 목록에 저장
            - 유효한 명령이면 이벤트로 변환
            - 래프트 합의 알고리즘이 여러 노드에 데이터 동기화
            - 동기화 완료 시 해당 이벤트가 실행
        11. 이벤트가 동기화되면 파티션 2의 이벤트 소싱 프레임워크는 CQRS를 사용하여 데이터를 읽기 경로로 도ㅗㅇ기화
            - 읽기 경로는 상태 및 실행 상태 재구성
        12. 파티션 2의 읽기 경로는 이벤트 소싱 프레임워크를 호출한 사가 조정자에 상태를 푸시
        13. 사가 조정자는 파티션 2로부터 성공 상태 수신
        14. 사가 조정자는 단계별 상태 테이블에 파티션 2의 작업이 성공했음을 나타내는 레코드 생성
        15. 모든 작업이 성공하고, 분산 트랜잭션이 완료되었으므로, 사가 조정자는 호출자에게 결과를 응답

## 4단계. 마무리

1. 인메모리 키-값 저장소 솔루션 -> 데이터 내구성 없음
2. 트랜잭션 기반 솔루션: 인메모리 캐시를 트랜잭션 데이터베이스로 바꾸고, 분산 트랜잭션 지원 위한 2PC, TC/C, SAGA 같은 프로토콜 사용 -> 데이터 감사 어려움
3. 이벤트 소싱 솔루션: 명령, 이벤트, 상태 데이터를 로컬 파일 시스템에 저장하여 성능 개선 -> SPOF 이슈
4. 안정성 높이기 위해 이벤트 목록 복제: 래프트 합의 알고리즘 사용
5. CRQS 개념 도입 + 외부 사용자에게 비동기 이벤트 소싱 프레임워크를 동기식 프레임워크로 제공하기 위한 역방향 프록시 도입 + TC/C, SAGA를 사용한 여러 노드에서의 명령 실행 조율
